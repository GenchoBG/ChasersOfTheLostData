{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "landings = pd.read_csv(\"Meteorite_Landings.csv\")\n",
    "thing = pd.read_csv(\"GLC03122015.csv\")\n",
    "fireball = pd.read_csv(\"Fireball_And_Bolide_Reports.csv\")\n",
    "comets = pd.read_csv(\"Near-Earth_Comets_-_Orbital_Elements.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze(dataset, cell, details = True):\n",
    "    values = dataset[cell].unique()\n",
    "    print(len(values))\n",
    "    print(values)\n",
    "    if(details):\n",
    "        for value in values:\n",
    "            print(value, ' -> ', len(dataset[dataset[cell] == value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45716\n",
      "45716\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nametype</th>\n",
       "      <th>recclass</th>\n",
       "      <th>mass (g)</th>\n",
       "      <th>fall</th>\n",
       "      <th>year</th>\n",
       "      <th>reclat</th>\n",
       "      <th>reclong</th>\n",
       "      <th>GeoLocation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Valid</td>\n",
       "      <td>L5</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Fell</td>\n",
       "      <td>01/01/1880 12:00:00 AM</td>\n",
       "      <td>50.77500</td>\n",
       "      <td>6.08333</td>\n",
       "      <td>(50.775, 6.08333)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Valid</td>\n",
       "      <td>H6</td>\n",
       "      <td>720.0</td>\n",
       "      <td>Fell</td>\n",
       "      <td>01/01/1951 12:00:00 AM</td>\n",
       "      <td>56.18333</td>\n",
       "      <td>10.23333</td>\n",
       "      <td>(56.18333, 10.23333)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Valid</td>\n",
       "      <td>EH4</td>\n",
       "      <td>107000.0</td>\n",
       "      <td>Fell</td>\n",
       "      <td>01/01/1952 12:00:00 AM</td>\n",
       "      <td>54.21667</td>\n",
       "      <td>-113.00000</td>\n",
       "      <td>(54.21667, -113.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Valid</td>\n",
       "      <td>Acapulcoite</td>\n",
       "      <td>1914.0</td>\n",
       "      <td>Fell</td>\n",
       "      <td>01/01/1976 12:00:00 AM</td>\n",
       "      <td>16.88333</td>\n",
       "      <td>-99.90000</td>\n",
       "      <td>(16.88333, -99.9)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Valid</td>\n",
       "      <td>L6</td>\n",
       "      <td>780.0</td>\n",
       "      <td>Fell</td>\n",
       "      <td>01/01/1902 12:00:00 AM</td>\n",
       "      <td>-33.16667</td>\n",
       "      <td>-64.95000</td>\n",
       "      <td>(-33.16667, -64.95)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  nametype     recclass  mass (g)  fall                    year    reclat  \\\n",
       "0    Valid           L5      21.0  Fell  01/01/1880 12:00:00 AM  50.77500   \n",
       "1    Valid           H6     720.0  Fell  01/01/1951 12:00:00 AM  56.18333   \n",
       "2    Valid          EH4  107000.0  Fell  01/01/1952 12:00:00 AM  54.21667   \n",
       "3    Valid  Acapulcoite    1914.0  Fell  01/01/1976 12:00:00 AM  16.88333   \n",
       "4    Valid           L6     780.0  Fell  01/01/1902 12:00:00 AM -33.16667   \n",
       "\n",
       "     reclong           GeoLocation  \n",
       "0    6.08333     (50.775, 6.08333)  \n",
       "1   10.23333  (56.18333, 10.23333)  \n",
       "2 -113.00000    (54.21667, -113.0)  \n",
       "3  -99.90000     (16.88333, -99.9)  \n",
       "4  -64.95000   (-33.16667, -64.95)  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# happily there is one data entry per metorite\n",
    "# we can discard the name\n",
    "print(len(landings[\"name\"]))\n",
    "print(len(landings[\"name\"].unique()))\n",
    "\n",
    "landings = landings.drop([\"name\", 'id'], axis = 1)\n",
    "landings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2148\n",
      "['03/07/2011 08:00:00 AM +0000' '04/01/2008 07:00:00 AM +0000'\n",
      " '01/30/2015 08:00:00 AM +0000' ... '12/22/2009 08:00:00 AM +0000'\n",
      " '09/27/2007 07:00:00 AM +0000' '11/18/2007 08:00:00 AM +0000']\n"
     ]
    }
   ],
   "source": [
    "#Useful\n",
    "analyze(thing, \"date_\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "['12/30/1899 08:00:00 AM +0000' nan '01/12/1900 08:00:00 AM +0000']\n",
      "12/30/1899 08:00:00 AM +0000  ->  1268\n",
      "nan  ->  0\n",
      "01/12/1900 08:00:00 AM +0000  ->  1\n"
     ]
    }
   ],
   "source": [
    "#Useless\n",
    "analyze(thing, \"time_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "['landslide' 'Lanslide']\n",
      "landslide  ->  6787\n",
      "Lanslide  ->  1\n"
     ]
    }
   ],
   "source": [
    "analyze(thing, \"hazard_typ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "['Mudslide' 'Landslide' 'Complex' 'Other' 'Rock_Fall' 'Debris_Flow'\n",
      " 'Rockfall' 'Snow_Avalanche' 'Unknown' 'Translational_Slide' 'mudslide'\n",
      " 'Creep' 'Lahar' 'Riverbank_Collapse' 'landslide']\n"
     ]
    }
   ],
   "source": [
    "analyze(thing, \"landslide_\", False)\n",
    "# TODO: Fix Landslide & landslide     rename - landslide_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165\n",
      "[nan 'Trami' 'Cyclone Giri' 'Hurricane Felix' '3 days of rain'\n",
      " 'Cyclone Nargis' 'Hudhud' 'Typhoon Kompasu' 'and Rain'\n",
      " 'Tropical Storm Richard' 'Wipha' 'Tropical Cyclone Hubert'\n",
      " 'Typhoon Morakot' 'Hurricane Tomas' 'Manuel' 'Lusi' 'Kong Rey'\n",
      " 'Typhoon Ketsana' 'Utor' 'Tropical Storm Olga' 'Typhoon Sinlaku'\n",
      " 'Typhoon Fanapi' 'Storm Xynthia' 'Luis' 'Typhoon Sepat' 'Typhoon Megi'\n",
      " 'Soulik' 'Hurricane Karl and Tropical Storm Matthew'\n",
      " 'Supertyphoon Juan (Megi)' 'Typhoon Chedeng (Songda)' 'Rammasun'\n",
      " 'Hurricane Beatriz' 'Santi' 'Tropical Storm Meranti'\n",
      " 'Tropical Storm Tomas' 'Mangkhut' 'Tropical Storm Dodong (Sarika)'\n",
      " 'Hurricane Dora' 'Cyclone Wilma' 'Tropical Storm Alma'\n",
      " 'Tropical Depression Parma' 'Typhoon Ondoy (Ketsana)' 'Neoguri (Florita)'\n",
      " 'Hurricane Frank' 'Haiyan' 'Tropical Cyclone Wilma' 'Toraji'\n",
      " 'Tropical Cyclone Maring' 'Typhoon No. 2 and March 11th earthquake'\n",
      " 'Usagi' 'Agaton' 'Hurricane Sandy' '1 hour of rain'\n",
      " 'Tropical Storm Kammuri' 'Hurricane Dean' 'Typhoon Chanthu' 'Mario'\n",
      " 'Kalmaegi' 'Typhoon Pepeng' 'Typhoon Hagupit' 'Ingrid' 'Manyi'\n",
      " 'Typhoon Glenda (Kompasu)' 'Tropical Depression Nando'\n",
      " 'Tropical Depression Nango' 'Typhoon Krosa' 'Tropical Storm Henry'\n",
      " 'Tropical Storm Henrietta' 'Tropical Storm Nicole'\n",
      " 'Tropical Storm Labuyo' 'Podul' 'Hurricane Gustav' 'Typhoon Jangmi'\n",
      " 'Volcanic Material' 'Tropical Storm Ondoy (Ketsana)'\n",
      " 'Tropical Cyclone Agatha' 'Nakri' 'Cyclone Laila' 'Hurricane Karl'\n",
      " 'Tropical Storm Lando' 'Tropical Storm Mina/Mitag' 'Hurricane Lorenzo'\n",
      " 'Typhoon Parma' 'Tropical Storm Otto' 'Tropical Cyclone Ida'\n",
      " 'Typhoon Aure(Aere), Bebeng' 'Collapsed retaining wall' 'Hurricane Igor'\n",
      " 'Tropical Storm Noel' 'Amang' 'Tropical Storm Isaac' 'Typhoon Basyang'\n",
      " 'Typhoon Lekima' 'Typhoon Julian' 'Seniang' 'Typhoon Wipha' 'Mina'\n",
      " 'El Nino' 'Tropical Depression Urduja' 'Typhoon Igme (Fung-Wong)'\n",
      " 'Tropical Depression Dodong (Sarika)' 'Tropical Depression 16'\n",
      " 'Tropical Storm Falcon' 'Tropical Storm Matthew' 'Typhoon Kiko'\n",
      " 'Typhoon Fung-Wong' 'Tropical Storm Fay' 'Typhoon Mina'\n",
      " 'Tropical Storm Arthur' 'Tropical Storm Kabayan' 'Tropical Storm Sandy'\n",
      " 'Hurricane Hannah' 'Pablo' 'Typhoon Nangka (Feria)'\n",
      " 'Two inches since Midnight' 'Typhoon Man-yi' 'Typhoon Nina'\n",
      " 'Typhoon Chan-hom' 'Nilam' 'Trudy' 'Bertha' 'Tropical Storm Alex'\n",
      " 'Typhoon Neoguri' 'Typhoon Nalgae (Quiel)' 'Typhoon Washin (Sendong)'\n",
      " 'Hurricane Alex' 'Typhoon Conson' 'Fernand' 'Typhon Morakot (Kiko)'\n",
      " 'Cyclone Aila' 'Volcanic eruptoin' 'Tropical Wave'\n",
      " 'Tropical Storm Dante (Kujira)' 'Typhoon Meranti'\n",
      " 'Typhoon Jangmi and Higos' 'Typhoon Karen' 'Typhoon Koppu'\n",
      " 'Typhoon Fengshen' 'Tropical Storm Ambro' 'Heaviest Rain in 48 years'\n",
      " 'Ivo' 'Tropical Storm Ofel' 'Tropical Storm Gustav'\n",
      " 'Tropical Depression Pepeng' 'Typhoon Etau'\n",
      " 'Tropical Storm Halong (Cosme)' 'Typhoon Nanmadol' 'Tropical Storm Cebu'\n",
      " 'Tropical Storm Arlene' 'Typhoon Kalmaegi' 'Ruby' 'Typhoon Ramon'\n",
      " 'Tropical Cyclone Quinta' 'Tropical Storm Paula' 'Winnie'\n",
      " 'Hurricane Dolly' 'Typhoon No. 15' 'Andrea' 'Typhoon Mirinae'\n",
      " 'Typhoon Ineng' 'Tropical Storm Irina' 'Typhoon No. 9' 'Hurricane Katia'\n",
      " 'Hurricane Jimena' 'Typhoon Cosme']\n",
      "nan  ->  0\n",
      "Trami  ->  12\n",
      "Cyclone Giri  ->  1\n",
      "Hurricane Felix  ->  3\n",
      "3 days of rain  ->  1\n",
      "Cyclone Nargis  ->  1\n",
      "Hudhud  ->  3\n",
      "Typhoon Kompasu  ->  1\n",
      "and Rain  ->  1\n",
      "Tropical Storm Richard  ->  1\n",
      "Wipha  ->  1\n",
      "Tropical Cyclone Hubert  ->  1\n",
      "Typhoon Morakot  ->  6\n",
      "Hurricane Tomas  ->  13\n",
      "Manuel  ->  5\n",
      "Lusi  ->  1\n",
      "Kong Rey  ->  1\n",
      "Typhoon Ketsana  ->  2\n",
      "Utor  ->  10\n",
      "Tropical Storm Olga  ->  5\n",
      "Typhoon Sinlaku  ->  3\n",
      "Typhoon Fanapi  ->  5\n",
      "Storm Xynthia  ->  1\n",
      "Luis  ->  1\n",
      "Typhoon Sepat  ->  3\n",
      "Typhoon Megi  ->  3\n",
      "Soulik  ->  2\n",
      "Hurricane Karl and Tropical Storm Matthew  ->  4\n",
      "Supertyphoon Juan (Megi)  ->  33\n",
      "Typhoon Chedeng (Songda)  ->  5\n",
      "Rammasun  ->  1\n",
      "Hurricane Beatriz  ->  1\n",
      "Santi  ->  2\n",
      "Tropical Storm Meranti  ->  1\n",
      "Tropical Storm Tomas  ->  14\n",
      "Mangkhut  ->  1\n",
      "Tropical Storm Dodong (Sarika)  ->  3\n",
      "Hurricane Dora  ->  5\n",
      "Cyclone Wilma  ->  3\n",
      "Tropical Storm Alma  ->  1\n",
      "Tropical Depression Parma  ->  23\n",
      "Typhoon Ondoy (Ketsana)  ->  2\n",
      "Neoguri (Florita)  ->  2\n",
      "Hurricane Frank  ->  2\n",
      "Haiyan  ->  2\n",
      "Tropical Cyclone Wilma  ->  2\n",
      "Toraji  ->  5\n",
      "Tropical Cyclone Maring  ->  1\n",
      "Typhoon No. 2 and March 11th earthquake  ->  1\n",
      "Usagi  ->  3\n",
      "Agaton  ->  20\n",
      "Hurricane Sandy  ->  3\n",
      "1 hour of rain  ->  1\n",
      "Tropical Storm Kammuri  ->  2\n",
      "Hurricane Dean  ->  4\n",
      "Typhoon Chanthu  ->  2\n",
      "Mario  ->  3\n",
      "Kalmaegi  ->  2\n",
      "Typhoon Pepeng  ->  1\n",
      "Typhoon Hagupit  ->  3\n",
      "Ingrid  ->  5\n",
      "Manyi  ->  3\n",
      "Typhoon Glenda (Kompasu)  ->  1\n",
      "Tropical Depression Nando  ->  1\n",
      "Tropical Depression Nango  ->  1\n",
      "Typhoon Krosa  ->  3\n",
      "Tropical Storm Henry  ->  1\n",
      "Tropical Storm Henrietta  ->  1\n",
      "Tropical Storm Nicole  ->  4\n",
      "Tropical Storm Labuyo  ->  2\n",
      "Podul  ->  1\n",
      "Hurricane Gustav  ->  4\n",
      "Typhoon Jangmi  ->  2\n",
      "Volcanic Material  ->  2\n",
      "Tropical Storm Ondoy (Ketsana)  ->  5\n",
      "Tropical Cyclone Agatha  ->  12\n",
      "Nakri  ->  1\n",
      "Cyclone Laila  ->  3\n",
      "Hurricane Karl  ->  1\n",
      "Tropical Storm Lando  ->  3\n",
      "Tropical Storm Mina/Mitag  ->  2\n",
      "Hurricane Lorenzo  ->  1\n",
      "Typhoon Parma  ->  4\n",
      "Tropical Storm Otto  ->  2\n",
      "Tropical Cyclone Ida  ->  4\n",
      "Typhoon Aure(Aere), Bebeng  ->  7\n",
      "Collapsed retaining wall  ->  6\n",
      "Hurricane Igor  ->  1\n",
      "Tropical Storm Noel  ->  5\n",
      "Amang  ->  2\n",
      "Tropical Storm Isaac  ->  1\n",
      "Typhoon Basyang  ->  2\n",
      "Typhoon Lekima  ->  2\n",
      "Typhoon Julian  ->  1\n",
      "Seniang  ->  6\n",
      "Typhoon Wipha  ->  1\n",
      "Mina  ->  2\n",
      "El Nino  ->  1\n",
      "Tropical Depression Urduja  ->  15\n",
      "Typhoon Igme (Fung-Wong)  ->  1\n",
      "Tropical Depression Dodong (Sarika)  ->  2\n",
      "Tropical Depression 16  ->  3\n",
      "Tropical Storm Falcon  ->  4\n",
      "Tropical Storm Matthew  ->  1\n",
      "Typhoon Kiko  ->  1\n",
      "Typhoon Fung-Wong  ->  2\n",
      "Tropical Storm Fay  ->  2\n",
      "Typhoon Mina  ->  1\n",
      "Tropical Storm Arthur  ->  2\n",
      "Tropical Storm Kabayan  ->  1\n",
      "Tropical Storm Sandy  ->  1\n",
      "Hurricane Hannah  ->  2\n",
      "Pablo  ->  1\n",
      "Typhoon Nangka (Feria)  ->  1\n",
      "Two inches since Midnight  ->  1\n",
      "Typhoon Man-yi  ->  1\n",
      "Typhoon Nina  ->  6\n",
      "Typhoon Chan-hom  ->  1\n",
      "Nilam  ->  1\n",
      "Trudy  ->  1\n",
      "Bertha  ->  1\n",
      "Tropical Storm Alex  ->  1\n",
      "Typhoon Neoguri  ->  1\n",
      "Typhoon Nalgae (Quiel)  ->  1\n",
      "Typhoon Washin (Sendong)  ->  1\n",
      "Hurricane Alex  ->  1\n",
      "Typhoon Conson  ->  1\n",
      "Fernand  ->  3\n",
      "Typhon Morakot (Kiko)  ->  3\n",
      "Cyclone Aila  ->  3\n",
      "Volcanic eruptoin  ->  1\n",
      "Tropical Wave  ->  1\n",
      "Tropical Storm Dante (Kujira)  ->  1\n",
      "Typhoon Meranti  ->  1\n",
      "Typhoon Jangmi and Higos  ->  1\n",
      "Typhoon Karen  ->  3\n",
      "Typhoon Koppu  ->  1\n",
      "Typhoon Fengshen  ->  4\n",
      "Tropical Storm Ambro  ->  1\n",
      "Heaviest Rain in 48 years  ->  1\n",
      "Ivo  ->  1\n",
      "Tropical Storm Ofel  ->  1\n",
      "Tropical Storm Gustav  ->  1\n",
      "Tropical Depression Pepeng  ->  1\n",
      "Typhoon Etau  ->  1\n",
      "Tropical Storm Halong (Cosme)  ->  3\n",
      "Typhoon Nanmadol  ->  1\n",
      "Tropical Storm Cebu  ->  4\n",
      "Tropical Storm Arlene  ->  1\n",
      "Typhoon Kalmaegi  ->  1\n",
      "Ruby  ->  2\n",
      "Typhoon Ramon  ->  2\n",
      "Tropical Cyclone Quinta  ->  1\n",
      "Tropical Storm Paula  ->  1\n",
      "Winnie  ->  1\n",
      "Hurricane Dolly  ->  1\n",
      "Typhoon No. 15  ->  1\n",
      "Andrea  ->  1\n",
      "Typhoon Mirinae  ->  1\n",
      "Typhoon Ineng  ->  1\n",
      "Tropical Storm Irina  ->  1\n",
      "Typhoon No. 9  ->  1\n",
      "Hurricane Katia  ->  1\n",
      "Hurricane Jimena  ->  1\n",
      "Typhoon Cosme  ->  1\n"
     ]
    }
   ],
   "source": [
    "# too little to give a fuck\n",
    "analyze(thing, \"storm_name\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "['Medium' 'Small' 'Large' 'Very_large' 'unknown' 'large' 'medium' 'small'\n",
      " 'Extra Large' nan]\n",
      "Medium  ->  4851\n",
      "Small  ->  1277\n",
      "Large  ->  482\n",
      "Very_large  ->  79\n",
      "unknown  ->  26\n",
      "large  ->  23\n",
      "medium  ->  33\n",
      "small  ->  14\n",
      "Extra Large  ->  1\n",
      "nan  ->  0\n"
     ]
    }
   ],
   "source": [
    "analyze(thing, \"landslide1\", True)\n",
    "#TODO: filter & rename - severity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "['glc' 'test' nan]\n",
      "glc  ->  6695\n",
      "test  ->  92\n",
      "nan  ->  0\n"
     ]
    }
   ],
   "source": [
    "#BS\n",
    "analyze(thing, \"cat_src\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "thing = thing.drop(['the_geom', \"hazard_typ\", 'OBJECTID', 'id', 'time_', \"storm_name\", 'source_nam', 'fatalities', 'injuries', 'source_lin', 'location_a', 'photos_lin', 'cat_src', 'cat_id', 'countrynam', 'adminname1', 'adminname2', 'population', 'countrycod', 'continentc', 'key_', 'version', 'user_id', 'tstamp', 'changeset_', 'distance', 'near', 'nearest_pl'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "thing.rename(columns={'landslide1':'severity', 'landslide_':'landslide_type', 'date_':'date'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>landslide_type</th>\n",
       "      <th>trigger</th>\n",
       "      <th>severity</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03/07/2011 08:00:00 AM +0000</td>\n",
       "      <td>United States</td>\n",
       "      <td>Mudslide</td>\n",
       "      <td>Downpour</td>\n",
       "      <td>Medium</td>\n",
       "      <td>41.5585</td>\n",
       "      <td>-73.4020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>04/01/2008 07:00:00 AM +0000</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Landslide</td>\n",
       "      <td>Rain</td>\n",
       "      <td>Medium</td>\n",
       "      <td>0.1115</td>\n",
       "      <td>113.9171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01/30/2015 08:00:00 AM +0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mudslide</td>\n",
       "      <td>Rain</td>\n",
       "      <td>Medium</td>\n",
       "      <td>52.3545</td>\n",
       "      <td>-127.6980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>09/24/2010 07:00:00 AM +0000</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Complex</td>\n",
       "      <td>Downpour</td>\n",
       "      <td>Medium</td>\n",
       "      <td>50.7053</td>\n",
       "      <td>-127.5062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>08/31/2014 07:00:00 AM +0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mudslide</td>\n",
       "      <td>Downpour</td>\n",
       "      <td>Small</td>\n",
       "      <td>53.3319</td>\n",
       "      <td>-132.4149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           date        country landslide_type   trigger  \\\n",
       "0  03/07/2011 08:00:00 AM +0000  United States       Mudslide  Downpour   \n",
       "1  04/01/2008 07:00:00 AM +0000      Indonesia      Landslide      Rain   \n",
       "2  01/30/2015 08:00:00 AM +0000            NaN       Mudslide      Rain   \n",
       "3  09/24/2010 07:00:00 AM +0000         Canada        Complex  Downpour   \n",
       "4  08/31/2014 07:00:00 AM +0000            NaN       Mudslide  Downpour   \n",
       "\n",
       "  severity  latitude  longitude  \n",
       "0   Medium   41.5585   -73.4020  \n",
       "1   Medium    0.1115   113.9171  \n",
       "2   Medium   52.3545  -127.6980  \n",
       "3   Medium   50.7053  -127.5062  \n",
       "4    Small   53.3319  -132.4149  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "['Medium' 'Small' 'Large' 'Very_large' 'unknown' 'large' 'medium' 'small'\n",
      " 'Extra Large' nan]\n",
      "Medium  ->  4851\n",
      "Small  ->  1277\n",
      "Large  ->  482\n",
      "Very_large  ->  79\n",
      "unknown  ->  26\n",
      "large  ->  23\n",
      "medium  ->  33\n",
      "small  ->  14\n",
      "Extra Large  ->  1\n",
      "nan  ->  0\n"
     ]
    }
   ],
   "source": [
    "analyze(thing, \"severity\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#analyze(thing, \"trigger\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: fix duplicates 'small' 'Small'\n",
    "#TODO: deal with date(timestamps) - Scaler\n",
    "#TODO: fix missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>landslide_type</th>\n",
       "      <th>trigger</th>\n",
       "      <th>severity</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03/07/2011 08:00:00 AM +0000</td>\n",
       "      <td>united states</td>\n",
       "      <td>mudslide</td>\n",
       "      <td>downpour</td>\n",
       "      <td>medium</td>\n",
       "      <td>41.5585</td>\n",
       "      <td>-73.4020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>04/01/2008 07:00:00 AM +0000</td>\n",
       "      <td>indonesia</td>\n",
       "      <td>landslide</td>\n",
       "      <td>rain</td>\n",
       "      <td>medium</td>\n",
       "      <td>0.1115</td>\n",
       "      <td>113.9171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01/30/2015 08:00:00 AM +0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mudslide</td>\n",
       "      <td>rain</td>\n",
       "      <td>medium</td>\n",
       "      <td>52.3545</td>\n",
       "      <td>-127.6980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>09/24/2010 07:00:00 AM +0000</td>\n",
       "      <td>canada</td>\n",
       "      <td>complex</td>\n",
       "      <td>downpour</td>\n",
       "      <td>medium</td>\n",
       "      <td>50.7053</td>\n",
       "      <td>-127.5062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>08/31/2014 07:00:00 AM +0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mudslide</td>\n",
       "      <td>downpour</td>\n",
       "      <td>small</td>\n",
       "      <td>53.3319</td>\n",
       "      <td>-132.4149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           date        country landslide_type   trigger  \\\n",
       "0  03/07/2011 08:00:00 AM +0000  united states       mudslide  downpour   \n",
       "1  04/01/2008 07:00:00 AM +0000      indonesia      landslide      rain   \n",
       "2  01/30/2015 08:00:00 AM +0000            NaN       mudslide      rain   \n",
       "3  09/24/2010 07:00:00 AM +0000         canada        complex  downpour   \n",
       "4  08/31/2014 07:00:00 AM +0000            NaN       mudslide  downpour   \n",
       "\n",
       "  severity  latitude  longitude  \n",
       "0   medium   41.5585   -73.4020  \n",
       "1   medium    0.1115   113.9171  \n",
       "2   medium   52.3545  -127.6980  \n",
       "3   medium   50.7053  -127.5062  \n",
       "4    small   53.3319  -132.4149  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thing['severity'] = thing['severity'].str.lower()\n",
    "thing['trigger'] = thing['trigger'].str.lower()\n",
    "thing['landslide_type'] = thing['landslide_type'].str.lower()\n",
    "thing['country'] = thing['country'].str.lower().replace('unitedâ\\xa0states', 'united states')\n",
    "thing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## we need to cure the unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "['medium' 'small' 'large' 'very_large' 'unknown' 'extra large' nan]\n",
      "medium  ->  4884\n",
      "small  ->  1291\n",
      "large  ->  505\n",
      "very_large  ->  79\n",
      "unknown  ->  26\n",
      "extra large  ->  1\n",
      "nan  ->  0\n"
     ]
    }
   ],
   "source": [
    "analyze(thing, \"severity\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "['downpour' 'rain' 'snowfall_snowmelt' 'unknown' 'earthquake'\n",
      " 'no_apparent_trigger' 'freeze_thaw' 'continuous_rain' 'construction'\n",
      " 'monsoon' 'tropical_cyclone' 'mining_digging' 'dam_embankment_collapse'\n",
      " 'other' 'snowfall' 'flooding']\n",
      "downpour  ->  3890\n",
      "rain  ->  1575\n",
      "snowfall_snowmelt  ->  45\n",
      "unknown  ->  338\n",
      "earthquake  ->  34\n",
      "no_apparent_trigger  ->  4\n",
      "freeze_thaw  ->  13\n",
      "continuous_rain  ->  271\n",
      "construction  ->  22\n",
      "monsoon  ->  70\n",
      "tropical_cyclone  ->  457\n",
      "mining_digging  ->  38\n",
      "dam_embankment_collapse  ->  4\n",
      "other  ->  12\n",
      "snowfall  ->  1\n",
      "flooding  ->  14\n"
     ]
    }
   ],
   "source": [
    "analyze(thing, \"trigger\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "['mudslide' 'landslide' 'complex' 'other' 'rock_fall' 'debris_flow'\n",
      " 'rockfall' 'snow_avalanche' 'unknown' 'translational_slide' 'creep'\n",
      " 'lahar' 'riverbank_collapse']\n",
      "mudslide  ->  1480\n",
      "landslide  ->  4752\n",
      "complex  ->  227\n",
      "other  ->  28\n",
      "rock_fall  ->  60\n",
      "debris_flow  ->  111\n",
      "rockfall  ->  101\n",
      "snow_avalanche  ->  6\n",
      "unknown  ->  4\n",
      "translational_slide  ->  2\n",
      "creep  ->  4\n",
      "lahar  ->  7\n",
      "riverbank_collapse  ->  6\n"
     ]
    }
   ],
   "source": [
    "analyze(thing, \"landslide_type\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138\n",
      "['united states' 'indonesia' nan 'canada' 'peru' 'myanmar (burma)'\n",
      " 'myanmar' 'new zealand' 'fiji' 'india' 'vanuatu' 'malaysia' 'tajikistan'\n",
      " 'china' 'australia' 'iceland' 'pakistan' 'argentina' 'nepal' 'brazil'\n",
      " 'uganda' 'kyrgyzstan' 'nicaragua' 'philippines' 'colombia' 'burma'\n",
      " 'bolivia' 'kenya' 'ecuador' 'united kingdom' 'bangladesh' 'tibet'\n",
      " 'papua new guinea' 'afghanistan' 'north korea' 'ethiopia' 'chile'\n",
      " 'nigeria' 'taiwan' 'honduras' 'japan' 'laos' 'madagascar' 'vietnam'\n",
      " 'trinidad and tobago' 'ghana' 'brunei' 'mexico' 'rwanda' 'sri lanka'\n",
      " 'malawi' 'thailand' 'scottland' 'bhutan' 'portugal' 'solomons island'\n",
      " 'norway' 'south africa' 'russia' 'iran' 'ireland' 'tasmania' 'guatemala'\n",
      " 'azerbaijan' 'costa rica' 'south korea' 'burkina faso' 'venezuela'\n",
      " 'georgia' 'jordan' 'democratic republic of congo' 'haiti' 'columbia'\n",
      " 'tajkikistan' 'tanzania' 'angola' 'france' 'phillipines' 'panama'\n",
      " 'bulgaria' 'slovakia' 'austria' 'albania' 'cuba' 'lebanon' 'turkey'\n",
      " 'scotland' 'jamaica' 'united arab emirates' 'switzerland' 'yemen'\n",
      " 'namibia' 'st vincent and the grenadines' 'sudan' 'singapore' 'armenia'\n",
      " 'germany' 'us virgin islands' 'el salvador' 'puerto rico'\n",
      " 'saint vincent and the grenadines' 'dominica' 'oman' 'ivory coast'\n",
      " 'st. vincent and the grenadines' 'bosnia' 'bosnia and herzegovina'\n",
      " 'dominican republic' 'grenada' 'greece' 'czech republic' 'macedonia'\n",
      " 'spain' 'slovenia' 'gabon' 'east timor' 'italy' 'st lucia' 'romania'\n",
      " 'sierra leone' 'algeria' 'barbados' 'swaziland' 'st. lucia'\n",
      " \"ivory coast (cote d'ivoire)\" 'guinea' 'israel' 'cameroon' 'serbia'\n",
      " 'bermuda' 'paraguay' 'kashmir' 'croatia' 'canary islands' 'ukraine'\n",
      " 'zambia' 'poland' 'solomon islands']\n",
      "united states  ->  1449\n",
      "indonesia  ->  288\n",
      "nan  ->  0\n",
      "canada  ->  104\n",
      "peru  ->  48\n",
      "myanmar (burma)  ->  25\n",
      "myanmar  ->  4\n",
      "new zealand  ->  88\n",
      "fiji  ->  29\n",
      "india  ->  893\n",
      "vanuatu  ->  1\n",
      "malaysia  ->  112\n",
      "tajikistan  ->  11\n",
      "china  ->  352\n",
      "australia  ->  79\n",
      "iceland  ->  2\n",
      "pakistan  ->  83\n",
      "argentina  ->  6\n",
      "nepal  ->  321\n",
      "brazil  ->  205\n",
      "uganda  ->  38\n",
      "kyrgyzstan  ->  6\n",
      "nicaragua  ->  18\n",
      "philippines  ->  555\n",
      "colombia  ->  83\n",
      "burma  ->  1\n",
      "bolivia  ->  9\n",
      "kenya  ->  44\n",
      "ecuador  ->  18\n",
      "united kingdom  ->  150\n",
      "bangladesh  ->  34\n",
      "tibet  ->  2\n",
      "papua new guinea  ->  12\n",
      "afghanistan  ->  10\n",
      "north korea  ->  4\n",
      "ethiopia  ->  1\n",
      "chile  ->  10\n",
      "nigeria  ->  10\n",
      "taiwan  ->  52\n",
      "honduras  ->  11\n",
      "japan  ->  53\n",
      "laos  ->  4\n",
      "madagascar  ->  3\n",
      "vietnam  ->  96\n",
      "trinidad and tobago  ->  62\n",
      "ghana  ->  5\n",
      "brunei  ->  14\n",
      "mexico  ->  59\n",
      "rwanda  ->  4\n",
      "sri lanka  ->  61\n",
      "malawi  ->  1\n",
      "thailand  ->  58\n",
      "scottland  ->  2\n",
      "bhutan  ->  19\n",
      "portugal  ->  5\n",
      "solomons island  ->  1\n",
      "norway  ->  17\n",
      "south africa  ->  17\n",
      "russia  ->  11\n",
      "iran  ->  6\n",
      "ireland  ->  20\n",
      "tasmania  ->  2\n",
      "guatemala  ->  41\n",
      "azerbaijan  ->  19\n",
      "costa rica  ->  49\n",
      "south korea  ->  10\n",
      "burkina faso  ->  1\n",
      "venezuela  ->  20\n",
      "georgia  ->  24\n",
      "jordan  ->  1\n",
      "democratic republic of congo  ->  3\n",
      "haiti  ->  18\n",
      "columbia  ->  5\n",
      "tajkikistan  ->  1\n",
      "tanzania  ->  4\n",
      "angola  ->  3\n",
      "france  ->  7\n",
      "phillipines  ->  7\n",
      "panama  ->  12\n",
      "bulgaria  ->  12\n",
      "slovakia  ->  2\n",
      "austria  ->  10\n",
      "albania  ->  1\n",
      "cuba  ->  3\n",
      "lebanon  ->  7\n",
      "turkey  ->  13\n",
      "scotland  ->  1\n",
      "jamaica  ->  29\n",
      "united arab emirates  ->  1\n",
      "switzerland  ->  6\n",
      "yemen  ->  5\n",
      "namibia  ->  2\n",
      "st vincent and the grenadines  ->  1\n",
      "sudan  ->  1\n",
      "singapore  ->  1\n",
      "armenia  ->  3\n",
      "germany  ->  2\n",
      "us virgin islands  ->  1\n",
      "el salvador  ->  8\n",
      "puerto rico  ->  2\n",
      "saint vincent and the grenadines  ->  7\n",
      "dominica  ->  14\n",
      "oman  ->  1\n",
      "ivory coast  ->  3\n",
      "st. vincent and the grenadines  ->  2\n",
      "bosnia  ->  3\n",
      "bosnia and herzegovina  ->  5\n",
      "dominican republic  ->  13\n",
      "grenada  ->  2\n",
      "greece  ->  3\n",
      "czech republic  ->  3\n",
      "macedonia  ->  2\n",
      "spain  ->  10\n",
      "slovenia  ->  1\n",
      "gabon  ->  1\n",
      "east timor  ->  1\n",
      "italy  ->  47\n",
      "st lucia  ->  1\n",
      "romania  ->  3\n",
      "sierra leone  ->  7\n",
      "algeria  ->  1\n",
      "barbados  ->  1\n",
      "swaziland  ->  1\n",
      "st. lucia  ->  1\n",
      "ivory coast (cote d'ivoire)  ->  2\n",
      "guinea  ->  2\n",
      "israel  ->  2\n",
      "cameroon  ->  4\n",
      "serbia  ->  1\n",
      "bermuda  ->  1\n",
      "paraguay  ->  1\n",
      "kashmir  ->  3\n",
      "croatia  ->  1\n",
      "canary islands  ->  1\n",
      "ukraine  ->  1\n",
      "zambia  ->  1\n",
      "poland  ->  2\n",
      "solomon islands  ->  1\n"
     ]
    }
   ],
   "source": [
    "analyze(thing, \"country\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
